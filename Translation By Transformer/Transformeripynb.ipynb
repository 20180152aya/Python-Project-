{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk2bP2O2irCl",
        "outputId": "dd70754e-58da-46d8-df7f-b9c6e64bebae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from datasets import load_dataset\n",
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "c_yI-4wTiuB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(dataset, src_vocab, tgt_vocab, max_len):\n",
        "\n",
        "    data = []\n",
        "    for example in dataset:\n",
        "        src_sentence = example['translation']['ar']\n",
        "        tgt_sentence = example['translation']['en']\n",
        "        src_indices = [src_vocab.get(word, src_vocab['<unk>']) for word in src_sentence.split()]\n",
        "        tgt_indices = [tgt_vocab.get(word, tgt_vocab['<unk>']) for word in tgt_sentence.split()]\n",
        "        data.append((\n",
        "            torch.tensor(src_indices[:max_len], dtype=torch.long),\n",
        "            torch.tensor(tgt_indices[:max_len], dtype=torch.long),\n",
        "        ))\n",
        "    return data"
      ],
      "metadata": {
        "id": "1ts84szbixWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(sentences: List[str], max_vocab_size: int = 80000) -> dict:\n",
        "    vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "    word_freq = {}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence.split():\n",
        "            word_freq[word] = word_freq.get(word, 0) + 1\n",
        "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    for idx, (word, _) in enumerate(sorted_words[:max_vocab_size - len(vocab)], len(vocab)):\n",
        "        vocab[word] = idx\n",
        "    return vocab\n"
      ],
      "metadata": {
        "id": "iOcjAbePi0in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, embed_size, num_heads, num_layers, ff_hidden_dim, max_len):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, embed_size)\n",
        "        self.positional_encoding = self.create_positional_encoding(max_len, embed_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=ff_hidden_dim)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=ff_hidden_dim)\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
        "\n",
        "        self.fc_out = nn.Linear(embed_size, tgt_vocab_size)\n",
        "\n",
        "    def create_positional_encoding(self, max_len, embed_size):\n",
        "        pe = torch.zeros(max_len, embed_size)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * -(np.log(10000.0) / embed_size))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        return pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.src_embedding(src).to(device) + self.positional_encoding[:, :src.size(1), :].to(device)\n",
        "        tgt = self.tgt_embedding(tgt).to(device) + self.positional_encoding[:, :tgt.size(1), :].to(device)\n",
        "\n",
        "        memory = self.encoder(src.permute(1, 0, 2))\n",
        "        output = self.decoder(tgt.permute(1, 0, 2), memory)\n",
        "        return self.fc_out(output.permute(1, 0, 2))\n",
        "\n"
      ],
      "metadata": {
        "id": "EfqtAHT0i6aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "def train_model(model, data_loader, optimizer, criterion, num_epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for src, tgt in data_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(data_loader):.4f}\")"
      ],
      "metadata": {
        "id": "jfNHqpCgjL8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model, data_loader, src_vocab, tgt_vocab, device):\n",
        "    model.eval()\n",
        "    translations = []\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in data_loader:\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            predicted = torch.argmax(output, dim=-1)\n",
        "            for i in range(predicted.size(0)):\n",
        "                src_sentence = ' '.join([list(src_vocab.keys())[list(src_vocab.values()).index(word)] for word in src[i] if word != 0])\n",
        "                tgt_sentence = ' '.join([list(tgt_vocab.keys())[list(tgt_vocab.values()).index(word)] for word in predicted[i] if word != 0])\n",
        "                translations.append((src_sentence, tgt_sentence))\n",
        "    return translations"
      ],
      "metadata": {
        "id": "6atUTgCwjSOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "meFDyzjscjRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_file(file_path: str) -> Tuple[List[str], List[str]]:\n",
        "\n",
        "    src_sentences = []\n",
        "    tgt_sentences = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            if len(parts) == 2:\n",
        "                src_sentences.append(parts[0])\n",
        "                tgt_sentences.append(parts[1])\n",
        "    return src_sentences, tgt_sentences"
      ],
      "metadata": {
        "id": "mn14uHfljZXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"ara_.txt\"\n",
        "src_sentences, tgt_sentences = load_data_from_file(file_path)\n",
        "\n",
        "src_sentences_train, src_sentences_test, tgt_sentences_train, tgt_sentences_test = train_test_split(\n",
        "    src_sentences, tgt_sentences, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "src_vocab = build_vocab(src_sentences_train)\n",
        "tgt_vocab = build_vocab(tgt_sentences_train)\n",
        "\n",
        "train_data = preprocess_data(\n",
        "    [{\"translation\": {\"ar\": src, \"en\": tgt}} for src, tgt in zip(src_sentences_train, tgt_sentences_train)],\n",
        "    src_vocab, tgt_vocab, max_len=50\n",
        ")\n",
        "test_data = preprocess_data(\n",
        "    [{\"translation\": {\"ar\": src, \"en\": tgt}} for src, tgt in zip(src_sentences_test, tgt_sentences_test)],\n",
        "    src_vocab, tgt_vocab, max_len=50\n",
        ")"
      ],
      "metadata": {
        "id": "x2k8vBcUjdmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=32, collate_fn=collate_fn)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(src_vocab),\n",
        "    tgt_vocab_size=len(tgt_vocab),\n",
        "    embed_size=256,\n",
        "    num_heads=8,\n",
        "    num_layers=4,\n",
        "    ff_hidden_dim=512,\n",
        "    max_len=50\n",
        ").to(device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kCgV3V9ijhO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaff2749-4358-4b0a-9498-89b96ccf6874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab['<pad>'])\n",
        "\n",
        "train_model(model, train_loader, optimizer, criterion, num_epochs=100, device=device)\n",
        "\n",
        "translations = evaluate_model(model, test_loader, src_vocab, tgt_vocab, device)\n",
        "for src, tgt in translations[:10]:\n",
        "    print(f\"Source: {src}\\nTranslated: {tgt}\\n\")"
      ],
      "metadata": {
        "id": "4iD-aplYkHgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a5a53d-ec2b-4906-fd3b-ec09f24b1b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 8.5642\n",
            "Epoch 2/100, Loss: 7.6232\n",
            "Epoch 3/100, Loss: 7.0124\n",
            "Epoch 4/100, Loss: 6.4251\n",
            "Epoch 5/100, Loss: 5.8630\n",
            "Epoch 6/100, Loss: 5.3460\n",
            "Epoch 7/100, Loss: 4.8551\n",
            "Epoch 8/100, Loss: 4.3976\n",
            "Epoch 9/100, Loss: 3.9607\n",
            "Epoch 10/100, Loss: 3.5587\n",
            "Epoch 11/100, Loss: 3.1644\n",
            "Epoch 12/100, Loss: 2.8117\n",
            "Epoch 13/100, Loss: 2.4601\n",
            "Epoch 14/100, Loss: 2.1402\n",
            "Epoch 15/100, Loss: 1.8425\n",
            "Epoch 16/100, Loss: 1.5678\n",
            "Epoch 17/100, Loss: 1.3108\n",
            "Epoch 18/100, Loss: 1.0866\n",
            "Epoch 19/100, Loss: 0.8791\n",
            "Epoch 20/100, Loss: 0.7023\n",
            "Epoch 21/100, Loss: 0.5520\n",
            "Epoch 22/100, Loss: 0.4267\n",
            "Epoch 23/100, Loss: 0.3302\n",
            "Epoch 24/100, Loss: 0.2566\n",
            "Epoch 25/100, Loss: 0.2012\n",
            "Epoch 26/100, Loss: 0.1590\n",
            "Epoch 27/100, Loss: 0.1284\n",
            "Epoch 28/100, Loss: 0.1065\n",
            "Epoch 29/100, Loss: 0.0907\n",
            "Epoch 30/100, Loss: 0.0753\n",
            "Epoch 31/100, Loss: 0.0693\n",
            "Epoch 32/100, Loss: 0.0549\n",
            "Epoch 33/100, Loss: 0.0510\n",
            "Epoch 34/100, Loss: 0.0394\n",
            "Epoch 35/100, Loss: 0.0364\n",
            "Epoch 36/100, Loss: 0.0314\n",
            "Epoch 37/100, Loss: 0.0330\n",
            "Epoch 38/100, Loss: 0.0281\n",
            "Epoch 39/100, Loss: 0.0236\n",
            "Epoch 40/100, Loss: 0.0199\n",
            "Epoch 41/100, Loss: 0.0209\n",
            "Epoch 42/100, Loss: 0.0184\n",
            "Epoch 43/100, Loss: 0.0158\n",
            "Epoch 44/100, Loss: 0.0136\n",
            "Epoch 45/100, Loss: 0.0129\n",
            "Epoch 46/100, Loss: 0.0168\n",
            "Epoch 47/100, Loss: 0.0218\n",
            "Epoch 48/100, Loss: 0.0160\n",
            "Epoch 49/100, Loss: 0.0135\n",
            "Epoch 50/100, Loss: 0.0126\n",
            "Epoch 51/100, Loss: 0.0097\n",
            "Epoch 52/100, Loss: 0.0087\n",
            "Epoch 53/100, Loss: 0.0066\n",
            "Epoch 54/100, Loss: 0.0084\n",
            "Epoch 55/100, Loss: 0.0095\n",
            "Epoch 56/100, Loss: 0.0090\n",
            "Epoch 57/100, Loss: 0.0062\n",
            "Epoch 58/100, Loss: 0.0063\n",
            "Epoch 59/100, Loss: 0.0053\n",
            "Epoch 60/100, Loss: 0.0099\n",
            "Epoch 61/100, Loss: 0.0107\n",
            "Epoch 62/100, Loss: 0.0101\n",
            "Epoch 63/100, Loss: 0.0053\n",
            "Epoch 64/100, Loss: 0.0053\n",
            "Epoch 65/100, Loss: 0.0048\n",
            "Epoch 66/100, Loss: 0.0060\n",
            "Epoch 67/100, Loss: 0.0068\n",
            "Epoch 68/100, Loss: 0.0085\n",
            "Epoch 69/100, Loss: 0.0053\n",
            "Epoch 70/100, Loss: 0.0051\n",
            "Epoch 71/100, Loss: 0.0034\n",
            "Epoch 72/100, Loss: 0.0031\n",
            "Epoch 73/100, Loss: 0.0052\n",
            "Epoch 74/100, Loss: 0.0028\n",
            "Epoch 75/100, Loss: 0.0032\n",
            "Epoch 76/100, Loss: 0.0035\n",
            "Epoch 77/100, Loss: 0.0061\n",
            "Epoch 78/100, Loss: 0.0046\n",
            "Epoch 79/100, Loss: 0.0039\n",
            "Epoch 80/100, Loss: 0.0036\n",
            "Epoch 81/100, Loss: 0.0036\n",
            "Epoch 82/100, Loss: 0.0079\n",
            "Epoch 83/100, Loss: 0.0047\n",
            "Epoch 84/100, Loss: 0.0036\n",
            "Epoch 85/100, Loss: 0.0039\n",
            "Epoch 86/100, Loss: 0.0024\n",
            "Epoch 87/100, Loss: 0.0022\n",
            "Epoch 88/100, Loss: 0.0015\n",
            "Epoch 89/100, Loss: 0.0034\n",
            "Epoch 90/100, Loss: 0.0040\n",
            "Epoch 91/100, Loss: 0.0048\n",
            "Epoch 92/100, Loss: 0.0033\n",
            "Epoch 93/100, Loss: 0.0031\n",
            "Epoch 94/100, Loss: 0.0034\n",
            "Epoch 95/100, Loss: 0.0033\n",
            "Epoch 96/100, Loss: 0.0046\n",
            "Epoch 97/100, Loss: 0.0033\n",
            "Epoch 98/100, Loss: 0.0048\n",
            "Epoch 99/100, Loss: 0.0015\n",
            "Epoch 100/100, Loss: 0.0016\n",
            "Source: It was very hot this afternoon.\n",
            "Translated: الجو حاراً جداً ظهيرة اليوم. اليوم. هذه الجو\n",
            "\n",
            "Source: Will you be home for <unk>\n",
            "Translated: ستكون في المنزل الورود التالي. لطفك. الجيد؟ الجيد؟\n",
            "\n",
            "Source: I don't recommend that.\n",
            "Translated: يمكنها بذلك. بذلك. بذلك. بذلك. بذلك. بذلك. بذلك.\n",
            "\n",
            "Source: Mom is older than Dad.\n",
            "Translated: أكبر من أبي عمراً. أكسجين. . . أكبر\n",
            "\n",
            "Source: My aunt was pleased with my success.\n",
            "Translated: عمتي ألّا أبداً. تجد تجد لتوم. البارحة. البارحة.\n",
            "\n",
            "Source: I would like to speak to the head nurse.\n",
            "Translated: التحدث إلى رئيس القسم اليوم؟ اليوم؟ اليوم؟ اليوم؟\n",
            "\n",
            "Source: I prefer coffee to tea.\n",
            "Translated: شرب القهوة على شرب الشاي. نوم. لساعات. .\n",
            "\n",
            "Source: I'll have to work hard.\n",
            "Translated: العمل بالسيارة. بجدّ. العمل العمل العمل عليك العمل\n",
            "\n",
            "Source: A big <unk> <unk> and a great many people lost their <unk>\n",
            "Translated: بمرارة. من من للقدوم للقدوم روما. اليوم؟ اليوم؟\n",
            "\n",
            "Source: Too much drinking will make you sick.\n",
            "Translated: من شرب أكسجين. أكسجين. . اليوم؟ اليوم؟ .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence: str, src_vocab: dict, tgt_vocab: dict, device: torch.device, max_len: int = 50000) -> str:\n",
        "\n",
        "    src_indices = [src_vocab.get(word, src_vocab['<unk>']) for word in sentence.split()]\n",
        "    src_tensor = torch.tensor(src_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "    tgt_indices = [tgt_vocab['<sos>']]\n",
        "    for _ in range(max_len):\n",
        "        tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        output = model(src_tensor, tgt_tensor)\n",
        "        next_word_idx = torch.argmax(output[0, -1, :]).item()\n",
        "\n",
        "\n",
        "        if next_word_idx == tgt_vocab['<eos>'] or (len(tgt_indices) > 1 and next_word_idx == tgt_indices[-1]):\n",
        "            break\n",
        "\n",
        "        tgt_indices.append(next_word_idx)\n",
        "\n",
        "\n",
        "    translated_sentence = ' '.join([list(tgt_vocab.keys())[list(tgt_vocab.values()).index(idx)] for idx in tgt_indices[1:] if idx != tgt_vocab['<eos>']])\n",
        "    return translated_sentence\n"
      ],
      "metadata": {
        "id": "NpevdBwwcOvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = \"لديه سيارته الخاصة\"\n",
        "translated_sentence = translate_sentence(model, input_sentence, src_vocab, tgt_vocab, device)\n",
        "print(f\"Input: {input_sentence}\")\n",
        "print(f\"Translated: {translated_sentence}\")\n"
      ],
      "metadata": {
        "id": "dtU0Z0zRcnng"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}